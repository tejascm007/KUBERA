# ============================================================================
# KUBERA STOCK ANALYSIS CHATBOT - DOCKER COMPOSE
# Docker Compose configuration for development and production
# ============================================================================

version: '3.8'

services:
  # ==========================================================================
  # POSTGRESQL DATABASE
  # ==========================================================================
  postgres:
    image: postgres:14-alpine
    container_name: kubera-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-kubera_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-kubera_password}
      POSTGRES_DB: ${POSTGRES_DB:-kubera_db}
      POSTGRES_INITDB_ARGS: "-E UTF8"
      TZ: Asia/Kolkata
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./app/db/migrations:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-kubera_user}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kubera-network

  # ==========================================================================
  # REDIS (Optional - for caching)
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: kubera-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kubera-network

  # ==========================================================================
  # KUBERA BACKEND API
  # ==========================================================================
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: kubera-backend
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      # App settings
      APP_ENV: ${APP_ENV:-production}
      DEBUG: ${DEBUG:-False}
      
      # Database
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-kubera_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-kubera_password}
      POSTGRES_DB: ${POSTGRES_DB:-kubera_db}
      
      # Redis
      REDIS_HOST: redis
      REDIS_PORT: 6379
      
      # Security
      SECRET_KEY: ${SECRET_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      
      # SMTP
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT}
      SMTP_USER: ${SMTP_USER}
      SMTP_PASSWORD: ${SMTP_PASSWORD}
      
      # Timezone
      TZ: Asia/Kolkata
    ports:
      - "8000:8000"
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads
      - ./mcp_servers:/app/mcp_servers:ro
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - kubera-network

  # ==========================================================================
  # PGADMIN (Optional - Database Management)
  # ==========================================================================
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: kubera-pgadmin
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@kubera.ai}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    networks:
      - kubera-network

# ============================================================================
# VOLUMES
# ============================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  pgadmin_data:
    driver: local

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  kubera-network:
    driver: bridge



# We use a  (formerly ) file to define and manage multi-container Docker applications using a single, human-readable configuration file. This eliminates the need for complex and repetitive  commands for each container and simplifies the overall application lifecycle management. [1, 2, 3, 4, 5]  
# Key Purposes and Benefits 

# • Orchestration of Multiple Containers: A typical application might require multiple services, such as a web server, a database, and a caching service (e.g., Nginx, PostgreSQL, and Redis). The YAML file defines how these separate services should run and interact. 
# • Simplified Configuration: The YAML format uses a simple, indentation-based structure to specify all the necessary configurations, such as which Docker images to use, port mappings, environment variables, volumes for data persistence, and network settings. 
# • Reproducibility and Consistency: By defining the entire application stack in a version-controlled file, the same consistent environment can be easily spun up on any developer's machine, testing server, or production environment. This helps prevent the "it works on my machine" problem. 
# • Single-Command Management: Once the services are defined in the YAML file, a single command, , is used to build, create, start, and link all the defined services and their dependencies simultaneously. 
# • Service Intercommunication: Docker Compose automatically creates a default network for all services in the file, allowing them to communicate with each other using their service names as hostnames without manual network configuration. 
# • Customization and Flexibility: You can use multiple Compose files (e.g.,  for base configuration and  for environment-specific settings) to customize behavior for different scenarios (development, production, testing). [2, 3, 4, 6, 7, 8, 9, 10, 11, 12]  

# In essence, the  file acts as a blueprint for your entire application stack, streamlining the development, testing, and deployment of multi-container applications. [5, 11]  


# Here is a step-by-step breakdown of how it works:
# The User Runs a Command: A user runs a command in their terminal, typically docker compose up or docker compose build.
# Docker Compose Reads the File: The Docker Compose software specifically looks for the compose.yaml file in the current directory. It reads the file line by line, parsing the YAML structure and understanding the user's desired configuration (e.g., "I need a service named 'webserver', running image 'nginx:latest', mapping port 80 to 8080, and mounting this specific folder as a volume").
# Docker Compose Issues Commands to the Docker Engine: Docker Compose acts as an orchestrator. It uses the configuration it read from the YAML file to send a series of precise instructions (API calls) to the main Docker Engine (the core service that manages containers on your computer).
# The Docker Engine Executes the Actions: The Docker Engine takes these instructions and executes them:
# It pulls necessary container images from a registry (like Docker Hub).
# It creates a dedicated network for the services to talk to each other.
# It starts individual containers according to the specified parameters (port mappings, environment variables, etc.).
# It links up volumes to persist data.
# In summary: The YAML file is not a program itself; it's a configuration instruction manual. The Docker Compose program is the "reader" that translates this manual into concrete actions performed by the computer's Docker Engine to build and run your application stack.

